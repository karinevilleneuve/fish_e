[["index.html", "Our dataset Alberta fishes Worklfows and their associated available databases Comparing pipelines with available databases Curating databases Taxonomy cross validation by identity (TAXXI)", " Our dataset 18 water samples collected from rivers and lakes near oil-sands extraction sites in the province of Alberta, Canada. Collected water was filtered and DNA collected on the filers was extracted and sequenced. For each sample collected, two different marker genes were used to amplify and sequence distinct DNA regions : the 12S ribosomal RNA gene and the mitochondrial cytochrome oxidase subunit (COI). Alberta fishes Fishbase was used to generate the following list of Alberta freshwater fishes. Worklfows and their associated available databases Links [1] Barcode of life (BOLD) [2] barque workflow [3] COI formatted for Barque [4] DADA2 workflow [5] Eukaryote CO1 Classifier [6] Mitochondrial Genome Database of Fish (MitoFish) [7] National Center for Biotechnology Information (NCBI) [8] Ribosomal Database Project (RDP) classifier [9] VSEARCH [10] 12S fish Classifier v1.0.1 [11] 12S formatted for barque Representation of Alberta freshwater fishes in databases Original code to evaluate if the fish from Alberta were present in each of the databases (3, 5 , 10, 11) can be found [here][Evaluation representation in databases]. Comparing pipelines with available databases DADA2 12S COI 839 ASV | from these 839 ASVs, 20 (2.38 %) are species with a bootstrap level above 70 % | from these 20 species, 8 (40 %) are from class actinopteri | from these 8 actinopteri, 7 (87.5 %) are species of freshwater fishes found in Alberta. Barque Curating databases https://forum.qiime2.org/t/building-a-coi-database-from-bold-references/16129 Using seqkit tool to filter databases in order to keep only sequences of freshwater fishes found in Alberta seqkit grep -v -n -f id_list.txt in.fasta &gt; out.fasta Taxonomy cross validation by identity (TAXXI) Cross-validation by identity (CVI) models varying distances between query sequences and reference sequences. A reference with known taxonomies is split into test and training sets such that for all test sequences, the most similar training sequence has a given identity (d). This is repeated for different identities, enabling assessment of prediction accuracy at varying distances from the reference. Some important definitions : The lowest common rank (LCR) of two sequences is the lowest rank where both have the same taxon name. The most probable lowest common rank (MLR) for a pair of sequences with identity d is defined as the LCR with highest probability. MLRs can be summarized by giving the rank identity threshold (RIT) for each rank r. The rank identity threshold (RIT) for each rank r is defined as the minimum identity for which MLR(d) = r. For example, if MLR(100) = species, MLR(99) = genus, MLR(98) = genus, … MLR(94) = genus and MLR(93) = family, then RIT(species) = 100 and RIT(genus) = 94. The top-hit identity distribution (THID) is the distances from a reference database. - R is the reference dataset divided into four disjoint subsets S, T, W and Z. - S is the test set. - A is the training set formed by the union of T and W. - T is the set of top hits for sequences in S, which are constrained to have identities in the range d ± σ (where σ specifies the maximum allowed deviation from the desired identity (d)). - W contains reference sequences with identity &lt; d; these are retained to create the largest possible training set. - Z contains sequences which cannot be assigned to S, T or W without violating the identity constraint. Making a benchmark dataset The distmx_split_identity command from USEARCH divides sequences into subsets such that the top-hit identity is a given value. This is used to create test-training pairs for cross-validation by identity. Input is a distance matrix created by the calc_distmx command. As per methods described in Edgar (2018) maximum allowed deviation (σ) from d used : σ = 1% for d = 90% and σ = 0.5% for d = 99, 97 and 95%. Testing with available databases (barque COI [3], RDP COI V5.1.0 [5], RDP 12S [10] and barque 12S [11]).   Following code was adapted from Donhauser et al. (2024) and cross-validated with the USEARCH documentation. Remove tab spaces in sequence name (for RDP databases specifically) for i in *.fasta ; do sed -i &#39;s/\\t/;/g&#39; $i ; done To create the distance matrix the following code was executed from a bash script called run_distmx.sh using nohup. for i in *.fasta ; do ~/usearch -calc_distmx $i -maxdist 0.2 -termdist 0.3 -tabbedout ${i%%.*}_distmax.txt; done Notes : Issue with barque_coi : Memory limit of 32-bit process exceeded, 64-bit build required.. Size of COI databases, barque vs RDP : - barque_coi : 1,215,952,678 - rdp_coi : 1,708,094,361 To create training and test datasets at different % identity the following code was executed from a bash script called run_splitid.sh using nohup. for i in *.fasta ; do ~/usearch -distmx_split_identity ${i%%.*}_distmax.txt -mindist 0.025 -maxdist 0.035 -tabbedout ${i%%.*}.97.subsets.txt ~/usearch -distmx_split_identity ${i%%.*}_distmax.txt -mindist 0.045 -maxdist 0.055 -tabbedout ${i%%.*}.95.subsets.txt ~/usearch -distmx_split_identity ${i%%.*}_distmax.txt -mindist 0.095 -maxdist 0.105 -tabbedout ${i%%.*}.90.subsets.txt done Output is a tabbed text given by the -tabbedout option. Fields are: Col1 - Subset name : there are four subsets with names 1, 2, 1x and 2x. Col2 - Label1 : label1 is the label of a sequence in the subset given by Col1. Col3 - Label2 : label2 is the top hit in the other subset (1 or 2) Col4 - Dist : distance between Label1 and Label2. Subsets 1 and 2 have top hits to each other in the specified range. Subset 1x has lower identities with subset 2, and can therefore be added to the training set if subset 2 is the query set. Similarly, subset 2x has lower identities with subset 1 and can be added to the training set if subset 1 is the query for i in *.subsets.txt ; do awk &#39;$1==1 || $1==&quot;1x&quot; {print $2}&#39; $i &gt; $i.trainingIDs.txt; awk &#39;$1==2 {print $2}&#39; $i &gt; $i.testIDs.txt; done Create fasta file with test and training set at each identity based on list for i in *.trainingIDs.txt ; do seqkit grep -n -f $i ${i%%.*}.fasta &gt; $i.trainning.fasta ; done for i in *.testIDs.txt ; do seqkit grep -n -f $i ${i%%.*}.fasta &gt; $i.test.fasta ; done !!! To Do !!! Write script to rename files : replace period between database and ID with underscore Trainning benchmark dataset To train the newly generated training set for each identity level you need to generate a sequence file and a taxonomy file, each with special formatting requirements : Sequence file The sequence file must be in fasta format and contain a unique identifier without any white space. The accession number makes a good identifier. Anything after the first white space is ignored. The following are acceptable: &gt;DQ248313 ACGATTTTGACCCTTCGGGGTCGATCTCCAACCCT &gt;JF735302 k__Fungi;p__Ascomycota;c__Sordariomycetes;o__Hypocreales;f__Nectriaceae;g__Dactylonectria;s__Dactylonectria_anthuriicol CCGAGTTTTCAACTC Taxonomy file The taxonomy file is a tab-delimited text file beginning with a header giving the Sequence ID and names of ranks to be included, for example Domain, Phylum, Class, Order, Family, Genus, Species. The subsequent lines begin with the unique identifiers from the fasta file followed by the taxonomy for each sequence. There are two requirements for this file: There must be an entry for every rank in every line. Hyphen placeholders are allowed but are not recommended. “Convergent evolution” is not allowed. For example, the same genus cannot appear in two different families. If a rank does not exist, you can fill in the missing entries with hyphens as in the table below. This is what the script FormatRefDB.py in CONSTAX does, but I do not recommend doing this. Using a hyphen as a place holder leads to a “ragged” classification that cannot be properly sorted by rank. Another option is to fill in the empty spaces with made-up but meaningful ranks as in the table below. The prefixes indicate the highest rank available. The absence of hyphen placeholders means that classification will not be ragged but include all ranks. Thus it will be possible to select, sort, and merge ranks when analyzing your data later. If you have accession IDs you can download the taxonomy from NCBI, or in some cases, as with the UNITE reference files, you can parse it from the sequence headers. In either case, some scripting is required to get everything into proper form. We definitely do not want to try typing in tens of thousands of lines without making any mistakes! Seq_ID Kingdom Phylum Class Order Family Genus Species MG190602 Fungi Ascomycota Sordariomycetes Hypocreales o_Hypocreales o_f_Hypocreales Hypocreales_sp DQ655721 Fungi Ascomycota Sordariomycetes Hypocreales Nectriaceae f_Nectriaceae Nectriaceae_sp KM225681 Fungi Ascomycota Sordariomycetes Hypocreales Nectriaceae Thyronectria Thyronectria_lamyi MF120484 Fungi Ascomycota Sordariomycetes Hypocreales Nectriaceae Fusarium Fusarium_redolens Taxonomy format of RDP databases : &gt;NC_031563 cellularOrganisms;Eukaryota;Metazoa;Chordata;Actinopteri;Cypriniformes;Cyprinidae;Aspiolucius;Aspiolucius_esocinus Generated the following R script to parse header and generate the ready4train_seqs.fasta and ready4train_taxonomy.txt. !!! To do !!! What to do in cases where only few ranks are included in the sequence header (i.e. barque) ? !!! Extract sequence header using grep for i in *.trainning.fasta ; do grep -e &quot;&gt;&quot; my.fasta https://scikit-learn.org/stable/modules/cross_validation.html Edgar_anacapa_BLCA_classifier_test_config.sh to test for TAXXI matrics "],["code.html", "Code Evaluating representation in databases", " Code Evaluating representation in databases #### ------------------------- Load libraries ------------------------------------------------------#### library(Biostrings) library(tidyverse) #### ------------------------- Load list of Freshwater fishes from Alberta ------------------------- #### alberta_fish = read.csv(&quot;/home/kvilleneuve/fish_edna/database/fishbase_alberta_freswater.csv&quot;, header = TRUE, check.names = FALSE) alberta_fish$Species = gsub(&quot; &quot;, &quot;_&quot;, alberta_fish$Species) # Replace space to underscore ### ------------------------- Load the databases -------------------------------------------------- #### ## RDP classifier ## rdpcoi_raw = readDNAStringSet(&quot;/home/kvilleneuve/fish_edna/database/rdp_coiv5_1_0/mydata_ref/mytrainseq.fasta&quot;, format = &quot;fasta&quot;) rdp12s_raw = readDNAStringSet(&quot;/home/kvilleneuve/fish_edna/database/12Sfishclassifier/mydata_training/mytrainseq.fasta&quot;, format = &quot;fasta&quot;) ## barque ## barquecoi_raw = readDNAStringSet(&quot;/home/kvilleneuve/fish_edna/database/bold_coi_for_barque_2023-09-12.fasta&quot;, format = &quot;fasta&quot;) barque12s_raw = readDNAStringSet(&quot;/home/kvilleneuve/fish_edna/database/barque_12S.fasta&quot;, format = &quot;fasta&quot;) ### ------------------------- Parse databases dataframes ----------------------------------------- #### # Because the number of ranks differ between databases used with # the RDP classifier and the barque workflow they are processed separately ## RDP databases list_rdp_db = list(&quot;COI RDP&quot; = rdpcoi_raw, &quot;12S RDP&quot; = rdp12s_raw) list_rdp_taxa = list() i = 0 for (databases in list_rdp_db){ i = i + 1 rdp_db = as.data.frame(databases@ranges@NAMES) rdp_taxa = rdp_db %&gt;% separate(`databases@ranges@NAMES`, c(&quot;Domain&quot;, &quot;Superkingdom&quot;, &quot;Kingdom&quot;, &quot;Phylum&quot;, &quot;Class&quot;, &quot;Order&quot;, &quot;Family&quot;, &quot;Genus&quot;, &quot;Species&quot;), &quot;;&quot;) list_rdp_taxa[[i]] = rdp_taxa names(list_rdp_taxa)[i] = names(list_rdp_db[i]) } ## barque databases list_barque_db = list(&quot;12S barque&quot; = barque12s_raw, &quot;COI barque&quot; = barquecoi_raw) list_barque_taxa = list() i = 0 for (databases in list_barque_db){ i = i + 1 barque_db = as.data.frame(databases@ranges@NAMES) barque_taxa = barque_db %&gt;% separate(`databases@ranges@NAMES`, c(&quot;Family&quot;, &quot;Genus&quot;, &quot;sort_species&quot;), &quot;_&quot;) barque_taxa$Species = paste(barque_taxa$Genus,&quot;_&quot;,barque_taxa$sort_species, sep =&quot;&quot;) list_barque_taxa[[i]] = barque_taxa names(list_barque_taxa)[i] = names(list_barque_db[i]) } # After parsing each databases we combine them into as single list # then we filter out fishes which are not found in their list of Alberta freshwater fishes jointlist_all_db = c(list_rdp_taxa, list_barque_taxa) list_filtered_db = list() i = 0 for (databses in jointlist_all_db){ i = i + 1 filtered_db = databses %&gt;% filter(Species %in% unique(alberta_fish$Species)) filtered_db_df = as.data.frame(unique(filtered_db$Species)) names(filtered_db_df) = &quot;Species&quot; filtered_db_df[names(jointlist_all_db[i])] = &quot;Yes&quot; list_filtered_db[[i]] = filtered_db_df } filtered_df = Reduce(function(...) merge(..., all=T), list_filtered_db) ### ------------------------- Combine as dataframe as save output ----------------------------------------- #### final_df = merge(alberta_fish, filtered_df, by = &quot;Species&quot;, all = TRUE) final_df = gsub(&quot;_&quot;, &quot; &quot;, final_df$Species) write.csv(final_df, &quot;/home/kvilleneuve/fish_edna/results/represensation_albertafish_databases.csv&quot;, quote = FALSE) "],["supplementary-data.html", "Supplementary data", " Supplementary data "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
